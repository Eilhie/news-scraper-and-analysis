{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cornelius\\anaconda3\\envs\\notebook\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import re, string, nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teks</th>\n",
       "      <th>Media</th>\n",
       "      <th>Label</th>\n",
       "      <th>Link</th>\n",
       "      <th>Teks_Artikel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sepakbola</td>\n",
       "      <td>Detik.com</td>\n",
       "      <td>Liga Inggris</td>\n",
       "      <td>https://sport.detik.com/sepakbola/liga-inggris...</td>\n",
       "      <td>Daftar IsiKlasemen Liga InggrisJadwal Liga Ing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sepakbola</td>\n",
       "      <td>Detik.com</td>\n",
       "      <td>Liga Inggris</td>\n",
       "      <td>https://sport.detik.com/sepakbola/liga-inggris...</td>\n",
       "      <td>Liverpool-ManajerLiverpoolArne Slottanpa ragu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sepakbola</td>\n",
       "      <td>Detik.com</td>\n",
       "      <td>Liga Inggris</td>\n",
       "      <td>https://sport.detik.com/sepakbola/liga-inggris...</td>\n",
       "      <td>Manchester-PenampilanManchester Unitedmasih na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20Detik</td>\n",
       "      <td>Detik.com</td>\n",
       "      <td>Liga Inggris</td>\n",
       "      <td>https://20.detik.com/detikupdate/20250106-2501...</td>\n",
       "      <td>Pelatih Liverpool memuji permainan Manchester ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sepakbola</td>\n",
       "      <td>Detik.com</td>\n",
       "      <td>Liga Inggris</td>\n",
       "      <td>https://sport.detik.com/sepakbola/liga-inggris...</td>\n",
       "      <td>London-Para pemain topArsenalseperti Bukayo Sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Teks      Media         Label  \\\n",
       "0  Sepakbola  Detik.com  Liga Inggris   \n",
       "1  Sepakbola  Detik.com  Liga Inggris   \n",
       "2  Sepakbola  Detik.com  Liga Inggris   \n",
       "3    20Detik  Detik.com  Liga Inggris   \n",
       "4  Sepakbola  Detik.com  Liga Inggris   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://sport.detik.com/sepakbola/liga-inggris...   \n",
       "1  https://sport.detik.com/sepakbola/liga-inggris...   \n",
       "2  https://sport.detik.com/sepakbola/liga-inggris...   \n",
       "3  https://20.detik.com/detikupdate/20250106-2501...   \n",
       "4  https://sport.detik.com/sepakbola/liga-inggris...   \n",
       "\n",
       "                                        Teks_Artikel  \n",
       "0  Daftar IsiKlasemen Liga InggrisJadwal Liga Ing...  \n",
       "1  Liverpool-ManajerLiverpoolArne Slottanpa ragu ...  \n",
       "2  Manchester-PenampilanManchester Unitedmasih na...  \n",
       "3  Pelatih Liverpool memuji permainan Manchester ...  \n",
       "4  London-Para pemain topArsenalseperti Bukayo Sa...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('berita_scraped.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "Liga Indonesia             23\n",
       "Liga Inggris               22\n",
       "Liga Italia                22\n",
       "Liga Spanyol               22\n",
       "Olahraga Non Sepak Bola    24\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Label')['Label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Teks            0\n",
       "Media           0\n",
       "Label           0\n",
       "Link            0\n",
       "Teks_Artikel    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cornelius\\AppData\\Local\\Temp\\ipykernel_20620\\464078543.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Teks_Artikel': 'Teks'}, inplace=True)\n",
      "C:\\Users\\cornelius\\AppData\\Local\\Temp\\ipykernel_20620\\464078543.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cleaned_text'] = df['Teks'].apply(clean_text)\n",
      "C:\\Users\\cornelius\\AppData\\Local\\Temp\\ipykernel_20620\\464078543.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokens'] = df['cleaned_text'].apply(tokenize)\n",
      "C:\\Users\\cornelius\\AppData\\Local\\Temp\\ipykernel_20620\\464078543.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokens'] = df['tokens'].apply(remove_stopwords)\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    #Khusus stopword dalam bahasa Indonesia\n",
    "    stop_words = set(stopwords.words('indonesian'))\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "df = data[['Label', 'Teks_Artikel']]\n",
    "df.rename(columns={'Teks_Artikel': 'Teks'}, inplace=True)\n",
    "df['cleaned_text'] = df['Teks'].apply(clean_text)\n",
    "df['tokens'] = df['cleaned_text'].apply(tokenize)\n",
    "df['tokens'] = df['tokens'].apply(remove_stopwords)\n",
    "df['text'] = df['tokens'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"text\"],\n",
    "    df[\"Label\"],\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"Label\"],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_data(texts, labels, tokenizer, max_len=128):\n",
    "    # Convert all texts to strings\n",
    "    if hasattr(texts, \"astype\"):\n",
    "        texts = texts.astype(str)\n",
    "    else:\n",
    "        texts = [str(t) for t in texts]\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = tokenizer(\n",
    "        list(texts),\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Convert labels to tensor\n",
    "    if hasattr(labels, \"values\"):\n",
    "        labels = labels.values\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    return tokens, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping (1-stage): {'Liga Inggris': 0, 'Liga Italia': 1, 'Liga Spanyol': 2, 'Liga Indonesia': 3, 'Olahraga Non Sepak Bola': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\cornelius\\anaconda3\\envs\\notebook\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\cornelius\\anaconda3\\envs\\notebook\\Lib\\site-packages\\transformers\\training_args.py:1590: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "unique_labels_1stage = df[\"Label\"].unique()\n",
    "label_mapping_1stage = {label: idx for idx, label in enumerate(unique_labels_1stage)}\n",
    "print(\"Label mapping (1-stage):\", label_mapping_1stage)\n",
    "\n",
    "train_labels_1stage = train_labels.map(label_mapping_1stage)\n",
    "test_labels_1stage = test_labels.map(label_mapping_1stage)\n",
    "\n",
    "tokens_train_1stage, labels_train_1stage = tokenize_data(\n",
    "    train_texts, train_labels_1stage, tokenizer\n",
    ")\n",
    "tokens_test_1stage, labels_test_1stage = tokenize_data(\n",
    "    test_texts, test_labels_1stage, tokenizer\n",
    ")\n",
    "\n",
    "train_dataset_1stage = CustomDataset(tokens_train_1stage, labels_train_1stage)\n",
    "test_dataset_1stage = CustomDataset(tokens_test_1stage, labels_test_1stage)\n",
    "\n",
    "model_1stage = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label_mapping_1stage)\n",
    ")\n",
    "\n",
    "\n",
    "training_args_1stage = TrainingArguments(\n",
    "    output_dir=\"./results_1stage\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs_1stage\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    no_cuda=True, \n",
    ")\n",
    "\n",
    "trainer_1stage = Trainer(\n",
    "    model=model_1stage,\n",
    "    args=training_args_1stage,\n",
    "    train_dataset=train_dataset_1stage,\n",
    "    eval_dataset=test_dataset_1stage,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Fine-Tuning Classification with One Stage Model ======\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 01:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.629014</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.630500</td>\n",
       "      <td>1.620166</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.630500</td>\n",
       "      <td>1.616298</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Evaluating Classification with One Stage Model ======\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (1-stage model):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      1.00      0.30         4\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.17        23\n",
      "   macro avg       0.03      0.20      0.06        23\n",
      "weighted avg       0.03      0.17      0.05        23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cornelius\\anaconda3\\envs\\notebook\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\cornelius\\anaconda3\\envs\\notebook\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\cornelius\\anaconda3\\envs\\notebook\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"====== Fine-Tuning Classification with One Stage Model ======\")\n",
    "trainer_1stage.train()\n",
    "\n",
    "print(\"====== Evaluating Classification with One Stage Model ======\")\n",
    "predictions_1stage = trainer_1stage.predict(test_dataset_1stage)\n",
    "y_pred_1stage = np.argmax(predictions_1stage.predictions, axis=-1)\n",
    "print(\"Classification Report (1-stage model):\\n\")\n",
    "print(classification_report(labels_test_1stage, y_pred_1stage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 stage model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\cornelius\\anaconda3\\envs\\notebook\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\cornelius\\anaconda3\\envs\\notebook\\Lib\\site-packages\\transformers\\training_args.py:1590: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def map_to_binary_labels(label):\n",
    "    # 0 -> \"Olahraga Non Sepak Bola\", 1 -> otherwise\n",
    "    return 0 if label == \"Olahraga Non Sepak Bola\" else 1\n",
    "\n",
    "binary_train_labels = train_labels.map(map_to_binary_labels)\n",
    "binary_test_labels = test_labels.map(map_to_binary_labels)\n",
    "\n",
    "tokens_train_binary, labels_train_binary = tokenize_data(\n",
    "    train_texts, binary_train_labels, tokenizer\n",
    ")\n",
    "tokens_test_binary, labels_test_binary = tokenize_data(\n",
    "    test_texts, binary_test_labels, tokenizer\n",
    ")\n",
    "\n",
    "train_dataset_binary = CustomDataset(tokens_train_binary, labels_train_binary)\n",
    "test_dataset_binary = CustomDataset(tokens_test_binary, labels_test_binary)\n",
    "\n",
    "model_binary = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "training_args_binary = TrainingArguments(\n",
    "    output_dir=\"./results_binary\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs_binary\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    no_cuda=True,\n",
    ")\n",
    "\n",
    "trainer_binary = Trainer(\n",
    "    model=model_binary,\n",
    "    args=training_args_binary,\n",
    "    train_dataset=train_dataset_binary,\n",
    "    eval_dataset=test_dataset_binary,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Fine-Tuning Binary Model First Stage ======\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 01:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.556959</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.547900</td>\n",
       "      <td>0.520990</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.547900</td>\n",
       "      <td>0.511324</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Evaluating Binary Model First Stage ======\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Binary model):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.78      1.00      0.88        18\n",
      "\n",
      "    accuracy                           0.78        23\n",
      "   macro avg       0.39      0.50      0.44        23\n",
      "weighted avg       0.61      0.78      0.69        23\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cornelius\\anaconda3\\envs\\notebook\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\cornelius\\anaconda3\\envs\\notebook\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\cornelius\\anaconda3\\envs\\notebook\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"====== Fine-Tuning Binary Model First Stage ======\")\n",
    "trainer_binary.train()\n",
    "\n",
    "print(\"====== Evaluating Binary Model First Stage ======\")\n",
    "predictions_binary = trainer_binary.predict(test_dataset_binary)\n",
    "y_pred_binary = np.argmax(predictions_binary.predictions, axis=-1)\n",
    "print(\"Classification Report (Binary model):\\n\")\n",
    "print(classification_report(labels_test_binary, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Stage 2 Dataset Size: 71\n",
      "Test Stage 2 Dataset Size: 18\n"
     ]
    }
   ],
   "source": [
    "train_texts_stage2 = train_texts[binary_train_labels == 1]\n",
    "train_labels_stage2 = train_labels[binary_train_labels == 1]\n",
    "test_texts_stage2 = test_texts[binary_test_labels == 1]\n",
    "test_labels_stage2 = test_labels[binary_test_labels == 1]\n",
    "\n",
    "print(f\"\\nTrain Stage 2 Dataset Size: {len(train_texts_stage2)}\")\n",
    "print(f\"Test Stage 2 Dataset Size: {len(test_texts_stage2)}\")\n",
    "\n",
    "league_labels = {\n",
    "    \"Liga Inggris\": 0,\n",
    "    \"Liga Indonesia\": 1,\n",
    "    \"Liga Spanyol\": 2,\n",
    "    \"Liga Italia\": 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\cornelius\\anaconda3\\envs\\notebook\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\cornelius\\anaconda3\\envs\\notebook\\Lib\\site-packages\\transformers\\training_args.py:1590: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_labels_stage2_mapped = train_labels_stage2.map(league_labels)\n",
    "test_labels_stage2_mapped = test_labels_stage2.map(league_labels)\n",
    "\n",
    "tokens_train_2stage, labels_train_2stage = tokenize_data(\n",
    "    train_texts_stage2, train_labels_stage2_mapped, tokenizer\n",
    ")\n",
    "tokens_test_2stage, labels_test_2stage = tokenize_data(\n",
    "    test_texts_stage2, test_labels_stage2_mapped, tokenizer\n",
    ")\n",
    "\n",
    "train_dataset_2stage = CustomDataset(tokens_train_2stage, labels_train_2stage)\n",
    "test_dataset_2stage = CustomDataset(tokens_test_2stage, labels_test_2stage)\n",
    "\n",
    "model_2stage = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=4\n",
    ")\n",
    "\n",
    "training_args_2stage = TrainingArguments(\n",
    "    output_dir=\"./results_2stage\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs_2stage\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    no_cuda=True,  # <--- force CPU\n",
    "    # seed=42\n",
    ")\n",
    "\n",
    "trainer_2stage = Trainer(\n",
    "    model=model_2stage,\n",
    "    args=training_args_2stage,\n",
    "    train_dataset=train_dataset_2stage,\n",
    "    eval_dataset=test_dataset_2stage,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Fine-Tuning 4-League Model Second Stage ======\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 01:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.383295</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.390600</td>\n",
       "      <td>1.382902</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.390600</td>\n",
       "      <td>1.380077</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Evaluating 4-League Model Second Stage ======\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (2-stage, league model):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         4\n",
      "           1       0.80      0.80      0.80         5\n",
      "           2       1.00      0.20      0.33         5\n",
      "           3       0.50      0.50      0.50         4\n",
      "\n",
      "    accuracy                           0.61        18\n",
      "   macro avg       0.70      0.62      0.57        18\n",
      "weighted avg       0.72      0.61      0.57        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"====== Fine-Tuning 4-League Model Second Stage ======\")\n",
    "trainer_2stage.train()\n",
    "\n",
    "print(\"====== Evaluating 4-League Model Second Stage ======\")\n",
    "predictions_2stage = trainer_2stage.predict(test_dataset_2stage)\n",
    "y_pred_2stage = np.argmax(predictions_2stage.predictions, axis=-1)\n",
    "print(\"Classification Report (2-stage, league model):\\n\")\n",
    "print(classification_report(labels_test_2stage, y_pred_2stage))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
